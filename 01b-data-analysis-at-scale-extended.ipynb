{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"images/horizontal.png\" alt=\"Coiled logo\" width=\"415\" hspace=\"10\"/>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"images/dask_horizontal_no_pad.svg\" alt=\"Dask logo\" width=\"400\" hspace=\"10\" />\n",
    "</p>\n",
    "\n",
    "# Scalable Data Science\n",
    "\n",
    "In this notebook, we'll \n",
    "\n",
    "* Perform a basic analytics and ETL workflow on the NYC taxi dataset using Pandas;\n",
    "* Scale up this workflow to a dataset that doesn't fit in RAM using Dask;\n",
    "* (Optional) Scale out this workflow to leverage a cluster on the Cloud using Coiled.\n",
    "\n",
    "The workflow is intentionally boring so that we can see the power of scalable data science immediately: we'll load some data, convert some data types for more efficient storage, add a new column, perform some basic analytics, save the new DataFrame to file.\n",
    "\n",
    "In the notebooks that follow, we'll jump into more interesting examples, including machine learning.\n",
    "\n",
    "*A bit about me:* I'm Hugo Bowne-Anderson, Head of Data Science Evangelism and Marketing at [Coiled](coiled.io/). We build products that bring the power of scalable data science and machine learning to you, such as single-click hosted clusters on the cloud. We want to take the DevOps out of data science so you can get back to your real job. If you're interested in taking Coiled for a test drive, you can sign up for our [free Beta here](beta.coiled.io/).\n",
    "\n",
    "Before scaling up, let's look at a common workflow in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pandas: Convert CSV to Parquet and Engineer a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pandas-logo.svg\" alt=\"pandas logo\" style=\"width: 500px;\"/>\n",
    "\n",
    "In the following, we'll \n",
    "\n",
    "* use Pandas to load in part of the NYC taxi dataset from a CSV, \n",
    "* massage the data, \n",
    "* engineer a feature, \n",
    "* compute the average tip as a function of the number of passengers, and \n",
    "* save to [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) (far more efficient than CSV, but not human-readable).\n",
    "\n",
    "If you're following along in Binder, you won't be able to execute the code but you can read it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data from Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-{01..12}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge\n",
      "1,2019-01-01 00:46:40,2019-01-01 00:53:20,1,1.50,1,N,151,239,1,7,0.5,0.5,1.65,0,0.3,9.95,\n",
      "1,2019-01-01 00:59:47,2019-01-01 01:18:59,1,2.60,1,N,239,246,1,14,0.5,0.5,1,0,0.3,16.3,\n",
      "2,2018-12-21 13:48:30,2018-12-21 13:52:40,3,.00,1,N,236,236,1,4.5,0.5,0.5,0,0,0.3,5.8,\n",
      "2,2018-11-28 15:52:25,2018-11-28 15:55:45,5,.00,1,N,193,193,2,3.5,0.5,0.5,0,0,0.3,7.55,\n",
      "2,2018-11-28 15:56:57,2018-11-28 15:58:33,5,.00,2,N,193,193,2,52,0,0.5,0,0,0.3,55.55,\n",
      "2,2018-11-28 16:25:49,2018-11-28 16:28:26,5,.00,1,N,193,193,2,3.5,0.5,0.5,0,5.76,0.3,13.31,\n",
      "2,2018-11-28 16:29:37,2018-11-28 16:33:43,5,.00,2,N,193,193,2,52,0,0.5,0,0,0.3,55.55,\n",
      "1,2019-01-01 00:21:28,2019-01-01 00:28:37,1,1.30,1,N,163,229,1,6.5,0.5,0.5,1.25,0,0.3,9.05,\n",
      "1,2019-01-01 00:32:01,2019-01-01 00:45:39,1,3.70,1,N,229,7,1,13.5,0.5,0.5,3.7,0,0.3,18.5,\n"
     ]
    }
   ],
   "source": [
    "# Check out head of 1st file\n",
    "!head data_taxi/yellow_tripdata_2019-01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this will take at least several minutes to download the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate data locally with Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 4.69 s, total: 20.6 s\n",
      "Wall time: 22 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667787</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:57:36</td>\n",
       "      <td>2019-02-01 00:18:39</td>\n",
       "      <td>1</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667788</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:32:03</td>\n",
       "      <td>2019-01-31 23:33:11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667789</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:36:36</td>\n",
       "      <td>2019-01-31 23:36:40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667790</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:14:53</td>\n",
       "      <td>2019-01-31 23:15:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667791</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:12:49</td>\n",
       "      <td>2019-01-31 23:14:08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7667792 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2019-01-01 00:46:40   2019-01-01 00:53:20                1   \n",
       "1               1  2019-01-01 00:59:47   2019-01-01 01:18:59                1   \n",
       "2               2  2018-12-21 13:48:30   2018-12-21 13:52:40                3   \n",
       "3               2  2018-11-28 15:52:25   2018-11-28 15:55:45                5   \n",
       "4               2  2018-11-28 15:56:57   2018-11-28 15:58:33                5   \n",
       "...           ...                  ...                   ...              ...   \n",
       "7667787         2  2019-01-31 23:57:36   2019-02-01 00:18:39                1   \n",
       "7667788         2  2019-01-31 23:32:03   2019-01-31 23:33:11                1   \n",
       "7667789         2  2019-01-31 23:36:36   2019-01-31 23:36:40                1   \n",
       "7667790         2  2019-01-31 23:14:53   2019-01-31 23:15:20                1   \n",
       "7667791         2  2019-01-31 23:12:49   2019-01-31 23:14:08                1   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 1.50           1                  N           151   \n",
       "1                 2.60           1                  N           239   \n",
       "2                 0.00           1                  N           236   \n",
       "3                 0.00           1                  N           193   \n",
       "4                 0.00           2                  N           193   \n",
       "...                ...         ...                ...           ...   \n",
       "7667787           4.79           1                  N           263   \n",
       "7667788           0.00           1                  N           193   \n",
       "7667789           0.00           1                  N           264   \n",
       "7667790           0.00           1                  N           264   \n",
       "7667791           0.00           1                  N           193   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1          7.0    0.5      0.5        1.65   \n",
       "1                 246             1         14.0    0.5      0.5        1.00   \n",
       "2                 236             1          4.5    0.5      0.5        0.00   \n",
       "3                 193             2          3.5    0.5      0.5        0.00   \n",
       "4                 193             2         52.0    0.0      0.5        0.00   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "7667787             4             1         18.0    0.5      0.5        3.86   \n",
       "7667788           193             1          0.0    0.0      0.0        0.00   \n",
       "7667789           264             1          0.0    0.0      0.0        0.00   \n",
       "7667790             7             1          0.0    0.0      0.0        0.00   \n",
       "7667791           193             1          0.0    0.0      0.0        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    0.3          9.95   \n",
       "1                 0.0                    0.3         16.30   \n",
       "2                 0.0                    0.3          5.80   \n",
       "3                 0.0                    0.3          7.55   \n",
       "4                 0.0                    0.3         55.55   \n",
       "...               ...                    ...           ...   \n",
       "7667787           0.0                    0.3         23.16   \n",
       "7667788           0.0                    0.0          0.00   \n",
       "7667789           0.0                    0.0          0.00   \n",
       "7667790           0.0                    0.0          0.00   \n",
       "7667791           0.0                    0.0          0.00   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "...                       ...  \n",
       "7667787                   0.0  \n",
       "7667788                   0.0  \n",
       "7667789                   0.0  \n",
       "7667790                   0.0  \n",
       "7667791                   0.0  \n",
       "\n",
       "[7667792 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Import pandas and read in beginning of 1st file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    \"data_taxi/yellow_tripdata_2019-01.csv\", \n",
    "    #nrows=10000,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "tpep_pickup_datetime      object\n",
       "tpep_dropoff_datetime     object\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "RatecodeID                 int64\n",
       "store_and_fwd_flag        object\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "payment_type               int64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massage data types \n",
    "\n",
    "Before we convert to parquet format, let's clean up our types a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 3.61 s, total: 20.9 s\n",
      "Wall time: 21.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667787</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:57:36</td>\n",
       "      <td>2019-02-01 00:18:39</td>\n",
       "      <td>1</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667788</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:32:03</td>\n",
       "      <td>2019-01-31 23:33:11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667789</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:36:36</td>\n",
       "      <td>2019-01-31 23:36:40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667790</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:14:53</td>\n",
       "      <td>2019-01-31 23:15:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667791</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:12:49</td>\n",
       "      <td>2019-01-31 23:14:08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7667792 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2019-01-01 00:46:40   2019-01-01 00:53:20                1   \n",
       "1               1  2019-01-01 00:59:47   2019-01-01 01:18:59                1   \n",
       "2               2  2018-12-21 13:48:30   2018-12-21 13:52:40                3   \n",
       "3               2  2018-11-28 15:52:25   2018-11-28 15:55:45                5   \n",
       "4               2  2018-11-28 15:56:57   2018-11-28 15:58:33                5   \n",
       "...           ...                  ...                   ...              ...   \n",
       "7667787         2  2019-01-31 23:57:36   2019-02-01 00:18:39                1   \n",
       "7667788         2  2019-01-31 23:32:03   2019-01-31 23:33:11                1   \n",
       "7667789         2  2019-01-31 23:36:36   2019-01-31 23:36:40                1   \n",
       "7667790         2  2019-01-31 23:14:53   2019-01-31 23:15:20                1   \n",
       "7667791         2  2019-01-31 23:12:49   2019-01-31 23:14:08                1   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 1.50           1                  N           151   \n",
       "1                 2.60           1                  N           239   \n",
       "2                 0.00           1                  N           236   \n",
       "3                 0.00           1                  N           193   \n",
       "4                 0.00           2                  N           193   \n",
       "...                ...         ...                ...           ...   \n",
       "7667787           4.79           1                  N           263   \n",
       "7667788           0.00           1                  N           193   \n",
       "7667789           0.00           1                  N           264   \n",
       "7667790           0.00           1                  N           264   \n",
       "7667791           0.00           1                  N           193   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1          7.0    0.5      0.5        1.65   \n",
       "1                 246             1         14.0    0.5      0.5        1.00   \n",
       "2                 236             1          4.5    0.5      0.5        0.00   \n",
       "3                 193             2          3.5    0.5      0.5        0.00   \n",
       "4                 193             2         52.0    0.0      0.5        0.00   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "7667787             4             1         18.0    0.5      0.5        3.86   \n",
       "7667788           193             1          0.0    0.0      0.0        0.00   \n",
       "7667789           264             1          0.0    0.0      0.0        0.00   \n",
       "7667790             7             1          0.0    0.0      0.0        0.00   \n",
       "7667791           193             1          0.0    0.0      0.0        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    0.3          9.95   \n",
       "1                 0.0                    0.3         16.30   \n",
       "2                 0.0                    0.3          5.80   \n",
       "3                 0.0                    0.3          7.55   \n",
       "4                 0.0                    0.3         55.55   \n",
       "...               ...                    ...           ...   \n",
       "7667787           0.0                    0.3         23.16   \n",
       "7667788           0.0                    0.0          0.00   \n",
       "7667789           0.0                    0.0          0.00   \n",
       "7667790           0.0                    0.0          0.00   \n",
       "7667791           0.0                    0.0          0.00   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "...                       ...  \n",
       "7667787                   0.0  \n",
       "7667788                   0.0  \n",
       "7667789                   0.0  \n",
       "7667790                   0.0  \n",
       "7667791                   0.0  \n",
       "\n",
       "[7667792 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read in data, parse dates\n",
    "df = pd.read_csv(\n",
    "    \"data_taxi/yellow_tripdata_2019-01.csv\", \n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.41 s, sys: 2.1 s, total: 3.51 s\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Alter data types for efficiency\n",
    "df = df.astype({\n",
    "    \"VendorID\": \"uint8\",\n",
    "    \"passenger_count\": \"uint8\",\n",
    "    \"RatecodeID\": \"uint8\",\n",
    "    \"store_and_fwd_flag\": \"category\",\n",
    "    \"PULocationID\": \"uint16\",\n",
    "    \"DOLocationID\": \"uint16\",    \n",
    "})\n",
    "\n",
    "# Create new feature in dataset: tip_ratio\n",
    "df[\"tip_ratio\"] = df.tip_amount / df.total_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Compute average tip as a function of the number of passengers\n",
    "df.groupby(\"passenger_count\").tip_amount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_parquet(\"data_taxi/yellow_tripdata_2019-01.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Read from parquet and time it\n",
    "df = pd.read_parquet(\"data_taxi/yellow_tripdata_2019-01.parq\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap:** We have\n",
    "\n",
    "* used Pandas to load in part of the NYC taxi dataset from a CSV, \n",
    "* massaged the data, \n",
    "* engineered a feature, \n",
    "* computed the average tip as a function of the number of passengers, and \n",
    "* saved to [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) (far more efficient than CSV, but not human-readable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operate on many files in a for loop?\n",
    "\n",
    "We could do this, but it's unpleasant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for filename in glob(\"~/data/nyctaxi/yellow_tripdata_2019-*.parq\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    ...\n",
    "    df.to_parquet(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Dask locally to process the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dask_horizontal_no_pad.svg\" alt=\"Dask logo\" style=\"width: 500px;\"/>\n",
    "\n",
    "The full NYC taxi dataset won't even fit in the RAM of my laptop. Do I need a large or external cluster yet? No. First, I can take advantage of all the cores on my laptop in parallel. This is what we call *scaling up* our computation (out-of-core computing). Later we'll see how to *scale out* computation across a cluster.\n",
    "\n",
    "One way of doing this is with [Dask](dask.org/). As we're about to see, part of the value of Dask lies in its API being as close as possible to the PyData APIs we know and love, in this case, Pandas.\n",
    "\n",
    "In [the words of Matthew Rocklin](https://coiled.io/blog/history-dask/), core developer and co-maintainer of Dask and CEO of Coiled, there was a social goal of Dask:\n",
    "> Invent nothing. We wanted to be as familiar as possible to what users already knew in the PyData stack\n",
    "\n",
    "Let's do it!\n",
    "\n",
    "The plan:\n",
    "\n",
    "* use Dask to load in **all** of the NYC taxi dataset from 10+ CSVs (8+ GBs), \n",
    "* massage the data, \n",
    "* engineer a feature,\n",
    "* compute the average tip as a function of the number of passengers, and\n",
    "* save to [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) (far more efficient than CSV, but not human-readable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also dive into the basics of Dask and distributed compute (but we'll execute some code first and dive into this part while it runs!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dask parts, spin up a local cluster, and instantiate a Client\n",
    "from dask.distributed import LocalCluster, Client\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Import the full dataset (note the Dask API!)\n",
    "df = dd.read_csv(\n",
    "    \"data_taxi/yellow_tripdata_2019-*.csv\", \n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    dtype={'RatecodeID': 'float64',\n",
    "       'VendorID': 'float64',\n",
    "       'passenger_count': 'float64',\n",
    "       'payment_type': 'float64'}\n",
    "\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter data types for efficiency\n",
    "df = df.astype({\n",
    "    \"VendorID\": \"UInt8\",\n",
    "    \"passenger_count\": \"UInt8\",\n",
    "    \"RatecodeID\": \"UInt8\",\n",
    "    \"store_and_fwd_flag\": \"category\",\n",
    "    \"PULocationID\": \"UInt16\",\n",
    "    \"DOLocationID\": \"UInt16\",    \n",
    "})\n",
    "\n",
    "# Create new feature in dataset: tip_ratio\n",
    "df[\"tip_ratio\"] = df.tip_amount / df.total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Prepare to compute the average tip \n",
    "# as a function of the number of passengers\n",
    "mean_amount = df.groupby(\"passenger_count\").tip_amount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# compute the average tip as a function of the number of passengers\n",
    "mean_amount.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_parquet(\"data_taxi/yellow_tripdata_2019.parq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a Notes on what is happening in Dask and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will take some time to run so let's take this opportunity to see what is going on with Dask, Python, and the distributed computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components of Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask contains 3 main components and we have already see two of them above:\n",
    "* High-level collections in the form of Dask DataFrames (these set up the step of your computation);\n",
    "* Schedulers (these actually execute the computation, in this case, on a single machine).\n",
    "\n",
    "Let's get a sense for what these are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dask-components.svg\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly is this Dask DataFrame? A schematic is worth a thousand words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dask-dataframe.svg\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the Dask DataFrame is a large, virtual dataframe divided along the index into multiple Pandas DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask Schedulers, Workers, and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dask-cluster.svg\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work (Python code) is performed on a cluster, which consists of \n",
    "* a _scheduler_ (which manages and sends the work / tasks to the workers)\n",
    "* _workers_, which compute the tasks.\n",
    "\n",
    "The _client_ is \"the user-facing entry point for cluster users.\" What this means is that the client lives wherever you are writing your Python code and the client talks to the scheduler, passing it the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap:** We have\n",
    "\n",
    "* used Dask to load in **all** of the NYC taxi dataset from 10+ CSVs (8+ GBs), \n",
    "* massaged the data, \n",
    "* engineered a feature, \n",
    "* computed the average tip as a function of the number of passengers, and \n",
    "* saved to [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) (far more efficient than CSV, but not human-readable),\n",
    "* dived into the basic of Dask and distributed compute and understand the basic concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optional: Work directly from the cloud with Coiled \n",
    "\n",
    "<br>\n",
    "<img src=\"images/horizontal.png\" alt=\"Coiled logo\" style=\"width: 500px;\"/>\n",
    "<br>\n",
    "\n",
    "Here I'll spin up a cluster on Coiled to show you just how easy it can be. Note that to do so, I've also signed into the [Coiled Beta](beta.coiled.io/), pip installed `coiled`, and authenticated. You can do the same!\n",
    "\n",
    "The plan:\n",
    "\n",
    "* use Coiled to load in **all** of the NYC taxi dataset from 10+ CSVs (8+ GBs) on an AWS cluster, \n",
    "* massage the data, \n",
    "* engineer a feature, \n",
    "* compute the average tip as a function of the number of passengers, and \n",
    "* save to [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) (far more efficient than CSV, but not human-readable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "from dask.distributed import LocalCluster, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Software Environment\n",
    "coiled.create_software_environment(\n",
    "    name=\"my-software-env\",\n",
    "    conda=\"binder/environment.yml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control the resources of your cluster by creating a new cluster configuration\n",
    "coiled.create_cluster_configuration(\n",
    "    name=\"my-cluster-config\",\n",
    "    worker_memory=\"16 GiB\",\n",
    "    worker_cpu=4,\n",
    "    scheduler_memory=\"8 GiB\",\n",
    "    scheduler_cpu=2,\n",
    "    software=\"my-software-env\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spin up cluster, instantiate a Client\n",
    "cluster = coiled.Cluster(n_workers=10, configuration=\"my-cluster-config\")\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Read data into a Dask DataFrame\n",
    "df = dd.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv\", \n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    dtype={\n",
    "        'RatecodeID': 'float64',\n",
    "       'VendorID': 'float64',\n",
    "       'passenger_count': 'float64',\n",
    "       'payment_type': 'float64'\n",
    "    },\n",
    "    storage_options={\"anon\":True}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Prepare to compute the average tip \n",
    "# as a function of the number of passengers\n",
    "mean_amount = df.groupby(\"passenger_count\").tip_amount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Compute the average tip \n",
    "# as a function of the number of passengers\n",
    "mean_amount.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter data types for efficiency\n",
    "df = df.astype({\n",
    "    \"VendorID\": \"UInt8\",\n",
    "    \"passenger_count\": \"UInt8\",\n",
    "    \"RatecodeID\": \"UInt8\",\n",
    "    \"store_and_fwd_flag\": \"category\",\n",
    "    \"PULocationID\": \"UInt16\",\n",
    "    \"DOLocationID\": \"UInt16\",    \n",
    "})\n",
    "\n",
    "# Create new feature in dataset: tip_ratio\n",
    "df[\"tip_ratio\"] = df.tip_amount / df.total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_parquet(\"s3://hugo-coiled-tutorial/nyctaxi-2019.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap:** We have\n",
    "* used Coiled to load in **all** of the NYC taxi dataset from 10+ CSVs (10 GBs) on an AWS cluster, \n",
    "* massaged the data, \n",
    "* engineered a feature, \n",
    "* computed the average tip as a function of the number of passengers, and \n",
    "* saved to [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) (far more efficient than CSV, but not human-readable)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
