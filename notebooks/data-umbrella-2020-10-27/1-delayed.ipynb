{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/dask_horizontal.svg\"\n",
    "     width=\"45%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "     \n",
    "# Dask Delayed\n",
    "\n",
    "This notebook covers Dask's `delayed` interface and how it can be used to parallelize existing Python code and custom algorithms. Let's start by looking at a basic, non-parallelized example and then see how `dask.delayed` can help.\n",
    "\n",
    "# Basic example\n",
    "\n",
    "In the code cell below, we have two Python functions, `inc` and `add`, which increment and add together their inputs, respectively. We call these functions on input values to produce some output which we then print.\n",
    "\n",
    "*Tip*: the `%%time` at the top of the cell tells Jupyter to print out how long it took the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "def inc(i):\n",
    "    time.sleep(1)\n",
    "    return i + 1\n",
    "\n",
    "def add(a, b):\n",
    "    time.sleep(1)\n",
    "    return a + b\n",
    "\n",
    "a = 1\n",
    "b = 12\n",
    "\n",
    "# Increment a and b\n",
    "c = inc(a)\n",
    "d = inc(b)\n",
    "\n",
    "# Add results together\n",
    "output = add(c, d)\n",
    "\n",
    "print(f\"{output = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps in this computation can be encoded in the following task graph shown below\n",
    "\n",
    "![](images/inc-add.svg)\n",
    "\n",
    "In the above task graph:\n",
    "\n",
    "1. Circular nodes in the graph are Python function calls\n",
    "\n",
    "2. Square nodes are Python objects that are created by one task as output and can be used as inputs in another task\n",
    "\n",
    "3. Arrows represent dependencies between tasks\n",
    "\n",
    "From looking at the task graph, we can see there's an opportunity for parallelism here! The two `inc` calls are totally independent of one another, so they could be run at the same time in parallel. Let's see how we can use Dask's `delayed` interface to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dask.delayed` decorator\n",
    "\n",
    "Dask's `delayed` interface consists of a single `delayed` decorator which allows you to build up complex task graphs by lightly annotating normal Python functions. Dask can then execute the task graph (potentially in parallel). The idea is that you can take your existing Python code, apply a few `delayed` decorators, and then have a parallel version of your code.\n",
    "\n",
    "Let's revist our `inc` / `add` example from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from dask import delayed    # Import the delayed decorator\n",
    "\n",
    "@delayed                    # Wrap inc with delayed\n",
    "def inc(i):\n",
    "    time.sleep(1)\n",
    "    return i + 1\n",
    "\n",
    "@delayed                    # Wrap add with delayed\n",
    "def add(a, b):\n",
    "    time.sleep(1)\n",
    "    return a + b\n",
    "\n",
    "a = 1\n",
    "b = 12\n",
    "\n",
    "# Increment a and b\n",
    "c = inc(a)\n",
    "d = inc(b)\n",
    "\n",
    "# Add results together\n",
    "output = add(c, d)\n",
    "\n",
    "print(f\"{output = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That happened much faster! But notice that the above cell didn't print the expected result of `15`, instead it printed a `Delayed` object.\n",
    "\n",
    "That's because Dask `delayed` works by wraping function calls and **delaying their execution** (hence the name \"delayed\"). Instead of returning the result of a function call, `delayed` functions return `Delayed` objects which keep track of what we want to compute by automatically building a task graph for us.\n",
    "\n",
    "You can see the task graph for a `Delayed` object by calling its `visualize` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually compute a result of a `Delayed` object, call its `compute` method which will tell Dask to compute the task graph in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Compute result\n",
    "result = output.compute()\n",
    "print(f\"{result = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the parallel version of this computation took ~2s while the non-parallel version took ~3s. Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Delayed`` objects support several standard Python operations, each of which creates another ``Delayed`` object representing the result:\n",
    "\n",
    "- Arithamtic operators, e.g. `*`, `-`, `+`\n",
    "- Item access and slicing, e.g. `x[0]`, `x[1:3]`\n",
    "- Attribute access, e.g. `x.size`\n",
    "- Method calls, e.g. `x.index(0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `delayed` functions, we can easily build up a task graph for the particular computation we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inc(5)\n",
    "result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inc(5) * inc(7)\n",
    "result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (inc(5) * inc(7)) + 2\n",
    "result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Parallelize a for-loop\n",
    "\n",
    "Below we define three functions: `inc`, `double`, and `add`. We use these functions to perform some operations on a list (assigned to the `data` variable). For this exercise, use `delayed` to run these operations in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(0.5)\n",
    "    return x + 1\n",
    "\n",
    "def double(x):\n",
    "    time.sleep(0.5)\n",
    "    return 2 * x\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(0.5)\n",
    "    return x + y\n",
    "\n",
    "data = list(range(10))\n",
    "\n",
    "output = []\n",
    "for x in data:\n",
    "    a = inc(x)\n",
    "    b = double(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "total = sum(output)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/delayed-1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Parallelize a for-loop with conditional flow\n",
    "\n",
    "This exercise is similar to the previous, but now instead of always having `a = inc(x)` we sometimes increment `x` and sometimes double `x` depending on if `x` is an even number or not. For this exercise, we again want to use `delayed` to run these operations in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(0.5)\n",
    "    return x + 1\n",
    "\n",
    "def double(x):\n",
    "    time.sleep(0.5)\n",
    "    return 2 * x\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(0.5)\n",
    "    return x + y\n",
    "\n",
    "def is_even(x):\n",
    "    return not x % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = list(range(10))\n",
    "\n",
    "output = []\n",
    "for x in data:\n",
    "    if is_even(x):\n",
    "        a = inc(x)\n",
    "    else:\n",
    "        a = double(x)\n",
    "    b = double(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "total = sum(output)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/delayed-2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Parallelize Pandas' `read_csv`\n",
    "\n",
    "For this exercise we'll use CSV files from NYC's flight dataset. You can download the CSV files by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download NYC flight dataset\n",
    "%run prep.py -d flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use Python's `glob` module to get a list of all the CSV files in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"data/nycflights/*.csv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas' `read_csv` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) can be used to load a single CSV file for our datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(files[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to use `dask.delayed` to create a new `read_csv_parallel` function which reads in *all* the files in the dataset in parallel using `dask.delayed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/delayed-3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "\n",
    "- [Delayed documentation](https://docs.dask.org/en/latest/delayed.html)\n",
    "- [Delayed screencast](https://www.youtube.com/watch?v=SHqFmynRxVU)\n",
    "- [Delayed API](https://docs.dask.org/en/latest/delayed-api.html)\n",
    "- [Delayed examples](https://examples.dask.org/delayed.html)\n",
    "- [Delayed best practices](https://docs.dask.org/en/latest/delayed-best-practices.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Next, we'll move onto discussing [Dask DataFrames](2-dataframe.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
